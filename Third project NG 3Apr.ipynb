{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24c1616f",
   "metadata": {},
   "source": [
    "# Project 3 \n",
    "## Goal(s):\n",
    "\n",
    "Predict how fit the candidate is based on their available information (variable fit)\n",
    "\n",
    "## Success Metric(s):\n",
    "\n",
    "Rank candidates based on a fitness score.\n",
    "\n",
    "Re-rank candidates when a candidate is starred.\n",
    "\n",
    "## Bonus(es):\n",
    "\n",
    "We are interested in a robust algorithm, tell us how your solution works and show us how your ranking gets better with each starring action.\n",
    "\n",
    "How can we filter out candidates which in the first place should not be in this list?\n",
    "\n",
    "Can we determine a cut-off point that would work for other roles without losing high potential candidates?\n",
    "\n",
    "Do you have any ideas that we should explore so that we can even automate this procedure to prevent human bias?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "468d8ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear algebra\n",
    "import numpy as np \n",
    "\n",
    "# data processing\n",
    "import pandas as pd \n",
    "\n",
    "# data visualization\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import style\n",
    "\n",
    "# Algorithms\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "\n",
    "#Cross validation\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "\n",
    "#Other\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#class imbalance\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.utils import resample\n",
    "\n",
    "#embedding using BERT\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52630321",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c90b19c0",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5de0a11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "og_data = pd.read_excel('potential-talents.xlsx')\n",
    "data = og_data\n",
    "keywords = 'aspiring human resources'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "034c161a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 104 entries, 0 to 103\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   id          104 non-null    int64  \n",
      " 1   job_title   104 non-null    object \n",
      " 2   location    104 non-null    object \n",
      " 3   connection  104 non-null    object \n",
      " 4   fit         0 non-null      float64\n",
      "dtypes: float64(1), int64(1), object(3)\n",
      "memory usage: 4.2+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9079eb94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'job_title', 'location', 'connection', 'fit'], dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e1bf1bfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>fit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>104.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>52.500000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>30.166206</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>26.750000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>52.500000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>78.250000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>104.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id  fit\n",
       "count  104.000000  0.0\n",
       "mean    52.500000  NaN\n",
       "std     30.166206  NaN\n",
       "min      1.000000  NaN\n",
       "25%     26.750000  NaN\n",
       "50%     52.500000  NaN\n",
       "75%     78.250000  NaN\n",
       "max    104.000000  NaN"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36978b0",
   "metadata": {},
   "source": [
    "# Add controls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "497f45f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "controls = pd.DataFrame({\n",
    "    \"id\": [1111, 1112, 1113],\n",
    "    \"job_title\": ['Machine learning', 'NA', 'artist'], \"location\":['x','x','x'], \"connection\": [150, 0, 500], \"fit\": [0, 0, 0]\n",
    "}, index=[104, 105, 106])\n",
    "\n",
    "# Append a dataframe\n",
    "#\n",
    "data = data.append(controls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3f73d991",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>job_title</th>\n",
       "      <th>location</th>\n",
       "      <th>connection</th>\n",
       "      <th>fit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>103</td>\n",
       "      <td>Always set them up for Success</td>\n",
       "      <td>Greater Los Angeles Area</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>104</td>\n",
       "      <td>Director Of Administration at Excellence Logging</td>\n",
       "      <td>Katy, Texas</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>1111</td>\n",
       "      <td>Machine learning</td>\n",
       "      <td>x</td>\n",
       "      <td>150</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>1112</td>\n",
       "      <td>NA</td>\n",
       "      <td>x</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>1113</td>\n",
       "      <td>artist</td>\n",
       "      <td>x</td>\n",
       "      <td>500</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                         job_title  \\\n",
       "102   103                    Always set them up for Success   \n",
       "103   104  Director Of Administration at Excellence Logging   \n",
       "104  1111                                  Machine learning   \n",
       "105  1112                                                NA   \n",
       "106  1113                                            artist   \n",
       "\n",
       "                     location connection  fit  \n",
       "102  Greater Los Angeles Area      500+   NaN  \n",
       "103               Katy, Texas      500+   NaN  \n",
       "104                         x        150  0.0  \n",
       "105                         x          0  0.0  \n",
       "106                         x        500  0.0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ebf9a380",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>job_title</th>\n",
       "      <th>location</th>\n",
       "      <th>connection</th>\n",
       "      <th>fit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2019 C.T. Bauer College of Business Graduate (...</td>\n",
       "      <td>Houston, Texas</td>\n",
       "      <td>85</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Native English Teacher at EPIK (English Progra...</td>\n",
       "      <td>Kanada</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Aspiring Human Resources Professional</td>\n",
       "      <td>Raleigh-Durham, North Carolina Area</td>\n",
       "      <td>44</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>People Development Coordinator at Ryan</td>\n",
       "      <td>Denton, Texas</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Advisory Board Member at Celal Bayar University</td>\n",
       "      <td>İzmir, Türkiye</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Aspiring Human Resources Specialist</td>\n",
       "      <td>Greater New York City Area</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Student at Humber College and Aspiring Human R...</td>\n",
       "      <td>Kanada</td>\n",
       "      <td>61</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>HR Senior Specialist</td>\n",
       "      <td>San Francisco Bay Area</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Student at Humber College and Aspiring Human R...</td>\n",
       "      <td>Kanada</td>\n",
       "      <td>61</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Seeking Human Resources HRIS and Generalist Po...</td>\n",
       "      <td>Greater Philadelphia Area</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Student at Chapman University</td>\n",
       "      <td>Lake Forest, California</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>SVP, CHRO, Marketing &amp; Communications, CSR Off...</td>\n",
       "      <td>Houston, Texas Area</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Human Resources Coordinator at InterContinenta...</td>\n",
       "      <td>Atlanta, Georgia</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>2019 C.T. Bauer College of Business Graduate (...</td>\n",
       "      <td>Houston, Texas</td>\n",
       "      <td>85</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>2019 C.T. Bauer College of Business Graduate (...</td>\n",
       "      <td>Houston, Texas</td>\n",
       "      <td>85</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Native English Teacher at EPIK (English Progra...</td>\n",
       "      <td>Kanada</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>Aspiring Human Resources Professional</td>\n",
       "      <td>Raleigh-Durham, North Carolina Area</td>\n",
       "      <td>44</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>People Development Coordinator at Ryan</td>\n",
       "      <td>Denton, Texas</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>2019 C.T. Bauer College of Business Graduate (...</td>\n",
       "      <td>Houston, Texas</td>\n",
       "      <td>85</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>Native English Teacher at EPIK (English Progra...</td>\n",
       "      <td>Kanada</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>Aspiring Human Resources Professional</td>\n",
       "      <td>Raleigh-Durham, North Carolina Area</td>\n",
       "      <td>44</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>People Development Coordinator at Ryan</td>\n",
       "      <td>Denton, Texas</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>Advisory Board Member at Celal Bayar University</td>\n",
       "      <td>İzmir, Türkiye</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>Aspiring Human Resources Specialist</td>\n",
       "      <td>Greater New York City Area</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>Student at Humber College and Aspiring Human R...</td>\n",
       "      <td>Kanada</td>\n",
       "      <td>61</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                                          job_title  \\\n",
       "0    1  2019 C.T. Bauer College of Business Graduate (...   \n",
       "1    2  Native English Teacher at EPIK (English Progra...   \n",
       "2    3              Aspiring Human Resources Professional   \n",
       "3    4             People Development Coordinator at Ryan   \n",
       "4    5    Advisory Board Member at Celal Bayar University   \n",
       "5    6                Aspiring Human Resources Specialist   \n",
       "6    7  Student at Humber College and Aspiring Human R...   \n",
       "7    8                               HR Senior Specialist   \n",
       "8    9  Student at Humber College and Aspiring Human R...   \n",
       "9   10  Seeking Human Resources HRIS and Generalist Po...   \n",
       "10  11                      Student at Chapman University   \n",
       "11  12  SVP, CHRO, Marketing & Communications, CSR Off...   \n",
       "12  13  Human Resources Coordinator at InterContinenta...   \n",
       "13  14  2019 C.T. Bauer College of Business Graduate (...   \n",
       "14  15  2019 C.T. Bauer College of Business Graduate (...   \n",
       "15  16  Native English Teacher at EPIK (English Progra...   \n",
       "16  17              Aspiring Human Resources Professional   \n",
       "17  18             People Development Coordinator at Ryan   \n",
       "18  19  2019 C.T. Bauer College of Business Graduate (...   \n",
       "19  20  Native English Teacher at EPIK (English Progra...   \n",
       "20  21              Aspiring Human Resources Professional   \n",
       "21  22             People Development Coordinator at Ryan   \n",
       "22  23    Advisory Board Member at Celal Bayar University   \n",
       "23  24                Aspiring Human Resources Specialist   \n",
       "24  25  Student at Humber College and Aspiring Human R...   \n",
       "\n",
       "                               location connection  fit  \n",
       "0                        Houston, Texas         85  NaN  \n",
       "1                                Kanada      500+   NaN  \n",
       "2   Raleigh-Durham, North Carolina Area         44  NaN  \n",
       "3                         Denton, Texas      500+   NaN  \n",
       "4                        İzmir, Türkiye      500+   NaN  \n",
       "5            Greater New York City Area          1  NaN  \n",
       "6                                Kanada         61  NaN  \n",
       "7                San Francisco Bay Area      500+   NaN  \n",
       "8                                Kanada         61  NaN  \n",
       "9             Greater Philadelphia Area      500+   NaN  \n",
       "10              Lake Forest, California          2  NaN  \n",
       "11                  Houston, Texas Area      500+   NaN  \n",
       "12                     Atlanta, Georgia      500+   NaN  \n",
       "13                       Houston, Texas         85  NaN  \n",
       "14                       Houston, Texas         85  NaN  \n",
       "15                               Kanada      500+   NaN  \n",
       "16  Raleigh-Durham, North Carolina Area         44  NaN  \n",
       "17                        Denton, Texas      500+   NaN  \n",
       "18                       Houston, Texas         85  NaN  \n",
       "19                               Kanada      500+   NaN  \n",
       "20  Raleigh-Durham, North Carolina Area         44  NaN  \n",
       "21                        Denton, Texas      500+   NaN  \n",
       "22                       İzmir, Türkiye      500+   NaN  \n",
       "23           Greater New York City Area          1  NaN  \n",
       "24                               Kanada         61  NaN  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e5746d",
   "metadata": {},
   "source": [
    "Attributes:\n",
    "id : unique identifier for candidate (numeric)\n",
    "\n",
    "job_title : job title for candidate (text)\n",
    "\n",
    "location : geographical location for candidate (text)\n",
    "\n",
    "connections: number of connections candidate has, 500+ means over 500 (text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4ea6ee4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title:  ['2019 C.T. Bauer College of Business Graduate (Magna Cum Laude) and aspiring Human Resources professional'\n",
      " 'Native English Teacher at EPIK (English Program in Korea)'\n",
      " 'Aspiring Human Resources Professional'\n",
      " 'People Development Coordinator at Ryan'\n",
      " 'Advisory Board Member at Celal Bayar University'\n",
      " 'Aspiring Human Resources Specialist'\n",
      " 'Student at Humber College and Aspiring Human Resources Generalist'\n",
      " 'HR Senior Specialist'\n",
      " 'Seeking Human Resources HRIS and Generalist Positions'\n",
      " 'Student at Chapman University'\n",
      " 'SVP, CHRO, Marketing & Communications, CSR Officer | ENGIE | Houston | The Woodlands | Energy | GPHR | SPHR'\n",
      " 'Human Resources Coordinator at InterContinental Buckhead Atlanta'\n",
      " 'Aspiring Human Resources Management student seeking an internship'\n",
      " 'Seeking Human Resources Opportunities'\n",
      " 'Experienced Retail Manager and aspiring Human Resources Professional'\n",
      " 'Human Resources, Staffing and Recruiting Professional'\n",
      " 'Human Resources Specialist at Luxottica'\n",
      " 'Director of Human Resources North America, Groupe Beneteau'\n",
      " 'Retired Army National Guard Recruiter, office manager,  seeking a position in Human Resources.'\n",
      " 'Human Resources Generalist at ScottMadden, Inc.'\n",
      " 'Business Management Major and Aspiring Human Resources Manager'\n",
      " 'Aspiring Human Resources Manager, seeking internship in Human Resources.'\n",
      " 'Human Resources Professional'\n",
      " 'Nortia Staffing is seeking Human Resources, Payroll & Administrative Professionals!!  (408) 709-2621'\n",
      " 'Aspiring Human Resources Professional | Passionate about helping to create an inclusive and engaging work environment'\n",
      " 'Human Resources|\\nConflict Management|\\nPolicies & Procedures|Talent Management|Benefits & Compensation'\n",
      " \"Human Resources Generalist at Schwan's\"\n",
      " 'Liberal Arts Major. Aspiring Human Resources Analyst.'\n",
      " 'Junior MES Engineer| Information Systems'\n",
      " 'Senior Human Resources Business Partner at Heil Environmental'\n",
      " 'Aspiring Human Resources Professional | An energetic and Team-Focused Leader'\n",
      " 'HR Manager at Endemol Shine North America'\n",
      " 'Human Resources professional for the world leader in GIS software'\n",
      " 'RRP Brand Portfolio Executive at JTI (Japan Tobacco International)'\n",
      " 'Information Systems Specialist and Programmer with a love for data and organization.'\n",
      " 'Bachelor of Science in Biology from Victoria University of Wellington'\n",
      " 'Human Resources Management Major' 'Director Human Resources  at EY'\n",
      " 'Undergraduate Research Assistant at Styczynski Lab'\n",
      " 'Lead Official at Western Illinois University'\n",
      " 'Seeking employment opportunities within Customer Service or Patient Care'\n",
      " 'Admissions Representative at Community medical center long beach'\n",
      " 'Seeking Human  Resources Opportunities. Open to travel and relocation.'\n",
      " 'Student at Westfield State University'\n",
      " 'Student at Indiana University Kokomo - Business Management - \\nRetail Manager at Delphi Hardware and Paint'\n",
      " 'Student' 'Seeking Human Resources Position'\n",
      " 'Aspiring Human Resources Manager | Graduating May 2020 | Seeking an Entry-Level Human Resources Position in St. Louis'\n",
      " 'Human Resources Generalist at Loparex'\n",
      " 'Business Intelligence and Analytics at Travelers'\n",
      " 'Always set them up for Success'\n",
      " 'Director Of Administration at Excellence Logging' 'Machine learning'\n",
      " 'NA' 'artist']\n",
      "location:  ['Houston, Texas' 'Kanada' 'Raleigh-Durham, North Carolina Area'\n",
      " 'Denton, Texas' 'İzmir, Türkiye' 'Greater New York City Area'\n",
      " 'San Francisco Bay Area' 'Greater Philadelphia Area'\n",
      " 'Lake Forest, California' 'Houston, Texas Area' 'Atlanta, Georgia'\n",
      " 'Chicago, Illinois' 'Austin, Texas Area' 'Jackson, Mississippi Area'\n",
      " 'Greater Grand Rapids, Michigan Area' 'Virginia Beach, Virginia'\n",
      " 'Monroe, Louisiana Area' 'Greater Boston Area' 'San Jose, California'\n",
      " 'New York, New York' 'Dallas/Fort Worth Area'\n",
      " 'Amerika Birleşik Devletleri' 'Baton Rouge, Louisiana Area'\n",
      " 'Myrtle Beach, South Carolina Area' 'Chattanooga, Tennessee Area'\n",
      " 'Los Angeles, California' 'Highland, California' 'Gaithersburg, Maryland'\n",
      " 'Baltimore, Maryland' 'Milpitas, California' 'Greater Atlanta Area'\n",
      " 'Greater Chicago Area' 'Torrance, California' 'Long Beach, California'\n",
      " 'Bridgewater, Massachusetts' 'Lafayette, Indiana' 'Kokomo, Indiana Area'\n",
      " 'Las Vegas, Nevada Area' 'Cape Girardeau, Missouri'\n",
      " 'Greater Los Angeles Area' 'Katy, Texas' 'x']\n",
      "connections:  [85 '500+ ' 44 1 61 2 390 57 82 5 7 16 212 409 52 455 174 268 50 4 40 18\n",
      " 349 155 39 64 9 415 19 71 48 103 49 150 0 500]\n"
     ]
    }
   ],
   "source": [
    "print('title: ', data.job_title.unique())\n",
    "print('location: ', data.location.unique())\n",
    "print('connections: ', data.connection.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e683fb73",
   "metadata": {},
   "source": [
    "# Processing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ea179b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First we will normalize the connections to be between 0-1. We will count 500+ as 500\n",
    "\n",
    "# Function to normalize scores to between 0-1\n",
    "def normalize_score(score):\n",
    "    if score == '500+ ':\n",
    "        score = 500\n",
    "    return float(score)/500\n",
    "\n",
    "# Applying the function to the 'connection' column to create a new 'normalized_connections' column\n",
    "data['normalized_connections'] = data['connection'].apply(normalize_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1e77ce0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Downloading gensim-4.3.1-cp38-cp38-macosx_10_9_x86_64.whl (24.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.0/24.0 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting smart-open>=1.8.1\n",
      "  Downloading smart_open-6.3.0-py3-none-any.whl (56 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.8/56.8 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.18.5 in /opt/anaconda3/lib/python3.8/site-packages (from gensim) (1.22.4)\n",
      "Collecting scipy>=1.7.0\n",
      "  Downloading scipy-1.10.1-cp38-cp38-macosx_10_9_x86_64.whl (35.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.0/35.0 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: smart-open, scipy, gensim\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.6.2\n",
      "    Uninstalling scipy-1.6.2:\n",
      "      Successfully uninstalled scipy-1.6.2\n",
      "Successfully installed gensim-4.3.1 scipy-1.10.1 smart-open-6.3.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dcc2caf4",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'path/to/word2vec/model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-ff34aad73eab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Load the Word2Vec model and tokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWord2Vec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"path/to/word2vec/model\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(cls, rethrow, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1951\u001b[0m         \"\"\"\n\u001b[1;32m   1952\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1953\u001b[0;31m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWord2Vec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1954\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWord2Vec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1955\u001b[0m                 \u001b[0mrethrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/gensim/utils.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(cls, fname, mmap)\u001b[0m\n\u001b[1;32m    484\u001b[0m         \u001b[0mcompress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSaveLoad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_adapt_by_suffix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 486\u001b[0;31m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    487\u001b[0m         \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_specials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmmap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_lifecycle_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loaded\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/gensim/utils.py\u001b[0m in \u001b[0;36munpickle\u001b[0;34m(fname)\u001b[0m\n\u001b[1;32m   1458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1459\u001b[0m     \"\"\"\n\u001b[0;32m-> 1460\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1461\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_pickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'latin1'\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# needed because loading from S3 doesn't support readline()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/smart_open/smart_open_lib.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(uri, mode, buffering, encoding, errors, newline, closefd, opener, compression, transport_params)\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0mtransport_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m     fobj = _shortcut_open(\n\u001b[0m\u001b[1;32m    178\u001b[0m         \u001b[0muri\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/smart_open/smart_open_lib.py\u001b[0m in \u001b[0;36m_shortcut_open\u001b[0;34m(uri, mode, compression, buffering, encoding, errors, newline)\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0mopen_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'errors'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_builtin_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffering\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbuffering\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mopen_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'path/to/word2vec/model'"
     ]
    }
   ],
   "source": [
    "#We will then calculate the similarity between the job titles and the given keyword (stored as variable 'keywords' in the top of the code, at first it we use 'aspiring human resources')\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Load the Word2Vec model and tokenizer\n",
    "model = Word2Vec.load(\"path/to/word2vec/model\")\n",
    "tokenizer = lambda text: text.split()\n",
    "\n",
    "# Tokenize and encode the job titles using Word2Vec\n",
    "job_title_encodings = data[\"job_title\"].apply(\n",
    "    lambda title: np.mean([model.wv[word] for word in tokenizer(title)], axis=0)\n",
    ")\n",
    "\n",
    "# Compute the cosine similarity between the encoded job titles and the keyword\n",
    "keyword_encoding = np.mean([model.wv[word] for word in tokenizer(keywords)], axis=0)\n",
    "similarity_scores = np.vstack(job_title_encodings.apply(lambda encoding: cosine_similarity(encoding.reshape(1, -1), keyword_encoding.reshape(1, -1)))).ravel()\n",
    "\n",
    "# Add the similarity scores as a new column in the DataFrame\n",
    "data[\"similarity_score_2vec\"] = similarity_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f003e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will then calculate the similarity between the job titles and the given keyword (stored as variable 'keywords' in the top of the code, at first it we use 'aspiring human resources')\n",
    "\n",
    "# Load the BERT tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = AutoModel.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Tokenize and encode the job titles using BERT\n",
    "job_title_encodings = data[\"job_title\"].apply(\n",
    "    lambda title: model(**tokenizer(title, return_tensors=\"pt\")).pooler_output.detach().numpy()\n",
    ")\n",
    "\n",
    "# Compute the cosine similarity between the encoded job titles and the keyword\n",
    "keyword_encoding = model(**tokenizer(keywords, return_tensors=\"pt\")).pooler_output.detach().numpy()\n",
    "similarity_scores = np.vstack(job_title_encodings.apply(lambda encoding: cosine_similarity(encoding, keyword_encoding))).ravel()\n",
    "\n",
    "# Add the similarity scores as a new column in the DataFrame\n",
    "data[\"similarity_score\"] = similarity_scores\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f64ddfdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>job_title</th>\n",
       "      <th>location</th>\n",
       "      <th>connection</th>\n",
       "      <th>fit</th>\n",
       "      <th>normalized_connections</th>\n",
       "      <th>similarity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>70</td>\n",
       "      <td>Retired Army National Guard Recruiter, office ...</td>\n",
       "      <td>Virginia Beach, Virginia</td>\n",
       "      <td>82</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.759416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>86</td>\n",
       "      <td>Information Systems Specialist and Programmer ...</td>\n",
       "      <td>Gaithersburg, Maryland</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.757093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>94</td>\n",
       "      <td>Seeking Human  Resources Opportunities. Open t...</td>\n",
       "      <td>Amerika Birleşik Devletleri</td>\n",
       "      <td>415</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.755037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>66</td>\n",
       "      <td>Experienced Retail Manager and aspiring Human ...</td>\n",
       "      <td>Austin, Texas Area</td>\n",
       "      <td>57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.114</td>\n",
       "      <td>0.752354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>69</td>\n",
       "      <td>Director of Human Resources North America, Gro...</td>\n",
       "      <td>Greater Grand Rapids, Michigan Area</td>\n",
       "      <td>500+</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.742197</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                                          job_title  \\\n",
       "69  70  Retired Army National Guard Recruiter, office ...   \n",
       "85  86  Information Systems Specialist and Programmer ...   \n",
       "93  94  Seeking Human  Resources Opportunities. Open t...   \n",
       "65  66  Experienced Retail Manager and aspiring Human ...   \n",
       "68  69  Director of Human Resources North America, Gro...   \n",
       "\n",
       "                               location connection  fit  \\\n",
       "69             Virginia Beach, Virginia         82  NaN   \n",
       "85               Gaithersburg, Maryland          4  NaN   \n",
       "93          Amerika Birleşik Devletleri        415  NaN   \n",
       "65                   Austin, Texas Area         57  NaN   \n",
       "68  Greater Grand Rapids, Michigan Area      500+   NaN   \n",
       "\n",
       "    normalized_connections  similarity_score  \n",
       "69                   0.164          0.759416  \n",
       "85                   0.008          0.757093  \n",
       "93                   0.830          0.755037  \n",
       "65                   0.114          0.752354  \n",
       "68                   1.000          0.742197  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.sort_values(by='similarity_score', ascending=False)\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9cf2b536",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>job_title</th>\n",
       "      <th>location</th>\n",
       "      <th>connection</th>\n",
       "      <th>fit</th>\n",
       "      <th>normalized_connections</th>\n",
       "      <th>similarity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>104</td>\n",
       "      <td>1111</td>\n",
       "      <td>Machine learning</td>\n",
       "      <td>x</td>\n",
       "      <td>150</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.908728</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index    id         job_title location connection  fit  \\\n",
       "43    104  1111  Machine learning        x        150  0.0   \n",
       "\n",
       "    normalized_connections  similarity_score  \n",
       "43                     0.3          0.908728  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reset dataframe index\n",
    "find = data.reset_index()\n",
    "#find where the starred items are now\n",
    "find.loc[find['id'] == 1111]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100c278b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now make a new column fitness score based on an equation taking similarity_score and normalized_connections\n",
    "\n",
    "# calculate the new column based on the equation\n",
    "data['fitness_score'] = data['similarity_score'] * 0.9 + data['normalized_connections'] * 0.1\n",
    "data = data.sort_values(by='fitness_score', ascending=False)\n",
    "data.tail(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac7499a",
   "metadata": {},
   "source": [
    "# Starring candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf76017",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a new column named 'starred' and set all values to 0\n",
    "data['starred'] = 0\n",
    "\n",
    "# set the value of the 7th row in 'starred' to 1 as an example\n",
    "data.loc[7, 'starred'] = 1\n",
    "\n",
    "#update the fitness_score based on starring\n",
    "data['fitness_score'] = data['similarity_score'] * 0.9 + data['normalized_connections'] * 0.1 + data['starred']\n",
    "data = data.sort_values(by='fitness_score', ascending=False)\n",
    "# print the updated dataframe\n",
    "data.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06361ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the value of the 3rd, 4th, 5th, row in 'starred' to 1 as more example\n",
    "data.loc[27, 'starred'] = 1\n",
    "data.loc[55, 'starred'] = 1\n",
    "data.loc[100, 'starred'] = 1\n",
    "\n",
    "#update the fitness_score based on starring\n",
    "data['fitness_score'] = data['similarity_score'] * 0.9 + data['normalized_connections'] * 0.1 + data['starred']\n",
    "data = data.sort_values(by='fitness_score', ascending=False)\n",
    "# print the updated dataframe\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5743e6",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6cc189",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ranking_model(data):\n",
    "    #make x and y\n",
    "    feature_cols = ['normalized_connections', 'similarity_score']\n",
    "    X = data[feature_cols]\n",
    "    y = data.starred \n",
    "    \n",
    "    #split data into training and testing, check both have starred items\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "    # Make sure at least one example of data with positive supervisory signal is in the training set\n",
    "    print(\"Number of ranked items in training set:\", y_train.sum())\n",
    "    print(\"Number of ranked items in test set:\",y_test.sum())\n",
    "    while y_train.sum() ==0 or y_test.sum()== 0:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "        # Make sure at least one example of data with positive supervisory signal is in the training set\n",
    "        print(\"Number of ranked items in training set:\", y_train.sum())\n",
    "        print(\"Number of ranked items in test set:\",y_test.sum())\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2)\n",
    "    \n",
    "    #define queries\n",
    "    query_train = [X_train.shape[0]]\n",
    "    query_val = [X_val.shape[0]]\n",
    "    query_test = [X_test.shape[0]]\n",
    "\n",
    "    # Train the LightGBM model\n",
    "    \n",
    "    gbm = lgb.LGBMRanker(\n",
    "    objective=\"lambdarank\",\n",
    "    metric=\"ndcg\",)\n",
    "    \n",
    "    gbm.fit(X_train, y_train, group=query_train,\n",
    "        eval_set=[(X_val, y_val)], eval_group=[query_val],\n",
    "        eval_at=[5, 10, 20], early_stopping_rounds=50)\n",
    "\n",
    "\n",
    "    # predict on test set and return\n",
    "    return gbm.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4e3553",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = ranking_model(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cea6690",
   "metadata": {},
   "source": [
    "# Updating fitness and ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671c938c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rank based on model output\n",
    "df = data\n",
    "df['ranking'] = predictions\n",
    "df = df.sort_values(by=\"ranking\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7c1868",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb81843f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reset dataframe index\n",
    "df = df.reset_index()\n",
    "#find where the starred items are now\n",
    "df.loc[df['starred'] == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8895bf9a",
   "metadata": {},
   "source": [
    "Problem: Starred rows are dispersed through the newly ranked dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123455d8",
   "metadata": {},
   "source": [
    "# Trying with more starred candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789a2f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded349f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set some rows as 'starred' for more example\n",
    "data.loc[60, 'starred'] = 1\n",
    "data.loc[67, 'starred'] = 1\n",
    "data.loc[12, 'starred'] = 1\n",
    "data.loc[98, 'starred'] = 1\n",
    "data.loc[80, 'starred'] = 1\n",
    "data.loc[59, 'starred'] = 1\n",
    "data.loc[28, 'starred'] = 1\n",
    "data.loc[73, 'starred'] = 1\n",
    "data.loc[57, 'starred'] = 1\n",
    "\n",
    "#update the fitness_score based on starring\n",
    "data['fitness_score'] = data['similarity_score'] * 0.9 + data['normalized_connections'] * 0.1 + data['starred']\n",
    "data = data.sort_values(by='fitness_score', ascending=False)\n",
    "# print the updated dataframe\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b763dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = ranking_model(data)\n",
    "df = data\n",
    "df['ranking'] = predictions\n",
    "df = df.sort_values(by='ranking', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83844984",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f591b656",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reset dataframe index\n",
    "df = df.reset_index()\n",
    "#find where the starred items are now\n",
    "df.loc[df['starred'] == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937eb45a",
   "metadata": {},
   "source": [
    "## Result for ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8132cd53",
   "metadata": {},
   "source": [
    "I have ranked candidates based on a fitness score that incorporates cosine similarity and normalized connections. I then rerank if someone manually stars a candidate.\n",
    "I then built a lightgbm ranking model to train on the data with the y='starred' and reranked the data based on the rankings obtained.\n",
    "However I then see that my previously starred candidates don't all appear at the top of the new ranking as the model didn't train well on such a small positive class (n=4).\n",
    "Adding more starred candidates (n=10) and retraining also gives better but still not great results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4411440",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b286a5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b84393",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
